{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1_data_radhika.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "We will use The 20 Newsgroups dataset \n",
        "Dataset [homepage](http://qwone.com/~jason/20Newsgroups/): \n",
        "\n",
        "Scikit-learn includes some nice helper functions for retrieving the 20 Newsgroups dataset-- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html. We'll use them below to retrieve the dataset.\n",
        "\n",
        "Also look at results fron non- neural net models here : https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXScUokPqyPx"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "train = fetch_20newsgroups(subset='train',\n",
        "                           remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "test = fetch_20newsgroups(subset='test',\n",
        "                           remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5sJTwM6rC9v"
      },
      "source": [
        "from pathlib import Path\n",
        "folder=Path('/content/gdrive/My Drive/Teaching/NLP/12_Code_advanced_methods')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NS-Vxi0Pkt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5761bdf7-a48a-449a-947a-4d5e430d152a"
      },
      "source": [
        "print(train.data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV2eF-BiPrLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0fa732-ec1a-4dd8-ae6b-974bee81a5f7"
      },
      "source": [
        "print(train.target[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IqtsBCEPx-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e620dc-757a-4eca-aaaa-afa5f1d0dad4"
      },
      "source": [
        "train.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3v7ZzA2QHv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2651b397-8cef-4776-d360-4b4a69cc4d23"
      },
      "source": [
        "len(train.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NiOeWmbRV_G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "58ad8dc7-715c-4362-dd7f-fb9c8cad8cc4"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(train.target);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDnJG6_1Al9A"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns = ['text','label'])\n",
        "df['text'] = train.data\n",
        "df['label'] = train.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BukGNPSCzkWU",
        "outputId": "36fad51a-f49f-45a5-852e-0c2b5deb7cbc"
      },
      "source": [
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "15    599\n",
              "8     598\n",
              "9     597\n",
              "11    595\n",
              "13    594\n",
              "7     594\n",
              "14    593\n",
              "5     593\n",
              "12    591\n",
              "2     591\n",
              "3     590\n",
              "6     585\n",
              "1     584\n",
              "4     578\n",
              "17    564\n",
              "16    546\n",
              "0     480\n",
              "18    465\n",
              "19    377\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUcpQ-3zsbG",
        "outputId": "cb713b86-4418-4f97-e8b6-479227df8f71"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaqetizOzu7w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRabzx7Q0K9X"
      },
      "source": [
        "## Bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkjq4Ebk0MpZ"
      },
      "source": [
        "# For DistilBERT:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVjFVzii0Qks",
        "outputId": "50603869-eb5f-4ccb-a5a2-fde55d6af4c5"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emJ6w-Ec3eF9",
        "outputId": "038f073c-7877-4dc1-f2ac-648e355b7c64"
      },
      "source": [
        "df[\"text\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        I was wondering if anyone out there could enli...\n",
              "1        A fair number of brave souls who upgraded thei...\n",
              "2        well folks, my mac plus finally gave up the gh...\n",
              "3        \\nDo you have Weitek's address/phone number?  ...\n",
              "4        From article <C5owCB.n3p@world.std.com>, by to...\n",
              "                               ...                        \n",
              "11309    DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
              "11310    I have a (very old) Mac 512k and a Mac Plus, b...\n",
              "11311    I just installed a DX2-66 CPU in a clone mothe...\n",
              "11312    \\nWouldn't this require a hyper-sphere.  In 3-...\n",
              "11313    Stolen from Pasadena between 4:30 and 6:30 pm ...\n",
              "Name: text, Length: 11314, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5X8Tw4r7bpR",
        "outputId": "c9544b4c-e22b-4c29-8585-1053e8a6d85c"
      },
      "source": [
        "df['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         7\n",
              "1         4\n",
              "2         4\n",
              "3         1\n",
              "4        14\n",
              "         ..\n",
              "11309    13\n",
              "11310     4\n",
              "11311     3\n",
              "11312     1\n",
              "11313     8\n",
              "Name: label, Length: 11314, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlJHd8PP1f_s",
        "outputId": "13baf057-484f-4a43-dfc7-ec1873a3d80d"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcIFQy3F2cH5"
      },
      "source": [
        "Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8Ns7kqC_vA"
      },
      "source": [
        "## Truncating sequence length to 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCrNq7qP2dEx"
      },
      "source": [
        "tokenized = df.text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,max_length=512,truncation= True )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30NeIRVN3OZU"
      },
      "source": [
        "## Padding\n",
        "After tokenization, tokenized is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA4o59_a3O_H"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJLa5iUm8e-P",
        "outputId": "aecac7b5-bb8b-448f-806c-6ab8d2cd925f"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKr41Pko8sYC"
      },
      "source": [
        "## Masking\n",
        "If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Zhd6qq8tsb",
        "outputId": "fe5e158c-a09c-4111-c71b-4f7526c15d12"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k909vtyN8wjN"
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95HokPZR--8r"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYhIgHRE_Ya-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_mask, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABYb2FeQCacv"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-38NdMqbEDzW",
        "outputId": "35d13177-6ce6-4c3d-958d-1642cc54e265"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXf-HVEGEUPh",
        "outputId": "1f90f51d-da81-4085-80c6-5d6beebfc472"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWyIntSVF666"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyQZKJx_GMY_",
        "outputId": "1c7c5cfa-cd27-438c-bfe8-aed6d8e7aa41"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRUZeJ4GPrk"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX82s1CwGrNk",
        "outputId": "551e92ef-161d-4269-95a1-a999da22f42d"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHD9gmwaG2mj"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5k-MnlkG5Fx",
        "outputId": "d52b5059-2896-4428-8436-8dc76cb9ddf4"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0uplhJG_qE"
      },
      "source": [
        "## Model train test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83EVP7NNHAii"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1wo1hZEIQ0r",
        "outputId": "b7a8ec37-6e2f-45b7-a12a-bb001ee8770e"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6545668827342369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4mCGPaTLQN-"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. LogisticRegression(C=5.2))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnuNDd0sIRhl",
        "outputId": "c5f15316-09c4-4339-a5bf-4f9952e37f82"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6620714033227288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkcMqeQ8DzQD"
      },
      "source": [
        "# truncate sequence length to 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cA7YeBTDyGm"
      },
      "source": [
        "tokenized = df.text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,max_length=128,truncation= True )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnNwBuCQEEkY"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhTLC1l6EHua",
        "outputId": "64259279-5983-4605-98fb-ad3048c7b4f8"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CUE8oAlEJlb",
        "outputId": "4457d1eb-d66b-44d4-a325-740bf961ce3b"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pcbi9q0EOhC"
      },
      "source": [
        "input_ids = torch.tensor(padded) \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWusrpGMERg_"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_mask, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epoySgW9EUUU"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhmTsalgEW1N",
        "outputId": "a730c683-e3c5-4862-d6ff-ab4c132dffe3"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=18, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18, 128])\n",
            "torch.Size([18, 128])\n",
            "torch.Size([18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZmM5rodEdp3",
        "outputId": "11376b4a-f974-4a9c-826d-599ba010a973"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOmXlad6EibO"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoggdnC0El4c",
        "outputId": "e1054048-106e-4028-e732-713f13b7fd71"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNKVz4S9Ep3t"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rirq9MTfEs_7",
        "outputId": "fccdbde2-34e0-4435-b3c9-bf10f234e4fa"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnfAcgiWEviz"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmNk1SZGEx8a",
        "outputId": "e6677800-60a0-4fd8-c4f5-c492f53f2053"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrHj3hwSE1ZX"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_kcYiWKE4bH",
        "outputId": "15f530b6-67cd-432d-a61d-dcf436a3d1e4"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6358279316440777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sZl13rDE-Sd",
        "outputId": "0cd08437-6a6d-4845-eaea-93131f5a2f9a"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.630965005302227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSv6LnIFGq0"
      },
      "source": [
        "# Truncate Sequence Length to 140 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMHbyZsGFJIy"
      },
      "source": [
        "tokenized = df.text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,max_length=140,truncation= True )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mer5RyUsFMfr"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPs24rCpFRdh",
        "outputId": "5852296f-78a7-4b1f-8219-6b8d5f0fb071"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iDXj50uFT-l",
        "outputId": "a8d41736-4be7-4885-ca64-c72c8a24c6ce"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3joQIwIFWQ_"
      },
      "source": [
        "input_ids = torch.tensor(padded) \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zSRr_osFY-N"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_mask, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK1-jnvHFbWk"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIdBmmwVFd5b",
        "outputId": "dc237ed1-7b8b-4cda-b48b-7a14912d5aea"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=18, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18, 140])\n",
            "torch.Size([18, 140])\n",
            "torch.Size([18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNMuKoplFgua",
        "outputId": "1d60e95c-b29a-4311-c754-648f40bcf05b"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zEz8g12FkHI"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvrMZvsTFm4D",
        "outputId": "aa7d14aa-12b9-4a05-b170-52a3c2bf5ecb"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9PpRMi7Fpld"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNIeT97CFr86",
        "outputId": "513e0b87-af62-4151-e034-182fe850c915"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_1fEZwWFueM"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSIpFZ97FySC"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKiKuuqcF2J5",
        "outputId": "95120c36-8a28-4075-bf6b-454ac46b4856"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6288744843842073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzQwPybgF5vH",
        "outputId": "e2ea1395-6f78-427f-f040-c0b967b656c2"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6376811594202898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y-DM641F8sq"
      },
      "source": [
        "# B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWYFBcePMDND"
      },
      "source": [
        "#Truncate Head with max token equals 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7wwtHwQRlR"
      },
      "source": [
        "## to know the maximum length of sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe_OQuIMMEXj",
        "outputId": "e36dd86d-5178-4087-ddb8-73a686f271e7"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  52886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ym4zwaiP8uS"
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "decoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=512\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnVUX9avVCyE"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_VNsAEWxm_"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDl-Yqe8W40X"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMDjNpDKXDgk",
        "outputId": "4b8eca84-f02b-4f03-d08e-eb68770fdbf1"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M01MLn1sXHbv",
        "outputId": "c5371409-3684-48ba-b1df-196d65c11d1e"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDNF8PsYXKIc"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7B6mOIxXObe",
        "outputId": "de5d6d59-5c7e-4ea3-ce40-13e913d35fae"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxBXca6CXSf2"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YD-u9fqXUiD",
        "outputId": "2dd90d43-04e7-4b93-e49e-279fe5d92abe"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY2TRFfYXWOE"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQkevCnTXX72",
        "outputId": "bb96ad89-eab7-4950-eb4c-a622aa2207f7"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CuJfNaEXzq1"
      },
      "source": [
        "## Model train test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcVuIp6KX31v"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usfdiyS6X-Kn",
        "outputId": "dfc1d8a6-fa0f-4a6f-8289-48975449deb7"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6519740718915734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoQnP58yYAKS",
        "outputId": "53b97ba4-267d-4a64-95ad-6d860defd17d"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6546482856132909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be13hCjFYdrX"
      },
      "source": [
        "# Truncate Head with max token equal 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhTB66wYgH7"
      },
      "source": [
        "# Get last three tokens and truncate head\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "decoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=128\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6-jvM9xYsWe"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg6Duiu3YyRW"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP8m9raMY2eu"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbFGRa-WY6im",
        "outputId": "728c9e31-d8f0-4d79-b175-2306fe7694a0"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP_DuACUZKU6",
        "outputId": "c3ce4e60-94e0-4bdc-ed80-787056082097"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idI5wGIsZS2l"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQjq51w_ZZW-",
        "outputId": "fdf85885-a810-4588-9cd7-69dc04f5d570"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHTuTH4ZiIc"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRG9CfnjZj3o",
        "outputId": "a6fb5257-a432-4487-ed93-8f0fb435baac"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ouo-kcXZlmO"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__tA1kTfZoYE",
        "outputId": "dc956e7b-5d5b-47eb-b855-a2f0ca224c20"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrhfN34dcGzq"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2HOiCpOcLXW",
        "outputId": "0d6fcf35-5eed-4409-f0b9-0428f9688902"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6087212728344136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwttJXhecOh0",
        "outputId": "320e261b-a050-4d3b-8f68-ed299c7818ca"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.616825733474726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPS_adwcTuW"
      },
      "source": [
        "# Truncate tokens with max_length =140\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmKLw-acUx4"
      },
      "source": [
        "# Get last three tokens and truncate head\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "decoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=140\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBVp2VZaclom"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C3rSFPXcp8G"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvuL791csUk"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgSPlZgyc174",
        "outputId": "4b2adb6d-a7fd-4019-b20f-1b0c6b6ff403"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 140])\n",
            "torch.Size([16, 140])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW3GaPfsc454",
        "outputId": "e5f1c2ef-50ca-4fb6-8b05-e6c92bbde42b"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPx7RVXQc8uN"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knVgEwowc_QM",
        "outputId": "09f4d247-1c47-4b5a-81ce-fe56d0ce0712"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olshm366dCD1"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyMPqyxFdD3x",
        "outputId": "0a0974e6-6858-4a26-d21b-3e523ad0c104"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxWmzq-MdFkf"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYkX41PIdHWy",
        "outputId": "b4c9645e-534a-47a7-a5d1-ccd138d16300"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYG7j3wJdJLN"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oiiTMDfdMwh",
        "outputId": "b4260f37-39fe-49a6-cb3b-10e0a67af838"
      },
      "source": [
        "parameters = {'C': [0.001,0.01,0.1,1]}\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6174425456688274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Kej5rddO5t",
        "outputId": "6336cb0d-0e75-47a1-bd7a-1d09f2917c28"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6362672322375398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HESzV7Z9ej4b"
      },
      "source": [
        "# Truncate middle tokens in the beginining with max_length =512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D5pTxsbekkR"
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "decoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=512\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrkQjnzZfBEv"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evStXkSyfNAt"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GatrOR1WfPHY"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFte1mlfSFS",
        "outputId": "923ffd2b-c1d8-42f2-eaeb-1aac8402c838"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZCRvArtfUr2"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3yYXEMfidE",
        "outputId": "ff84ee9b-e738-49ff-fcc2-f0c1183ce284"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQCvmaTCfkRs"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-heAqKrMfmK3",
        "outputId": "e19d0a17-72d8-4bd1-89bc-3d85950c6cd8"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDnzP0R-fnww"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmABYZMLfphE",
        "outputId": "f194471e-0556-4ef6-9daf-7d0dc872941b"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HILDdn39frIh"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCpJZo5FfvVi",
        "outputId": "25a8019a-a13f-4278-df2b-257a31e9d035"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6591632292280496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYvqPp6Ifx1K",
        "outputId": "51070287-c398-426d-84e8-fb4d6eb439a8"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6595970307529162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnx0IoTf2-N"
      },
      "source": [
        "## Truncate middle tokens in the beginining with max_length **128**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BY3ABRef4tl"
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "docoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=128\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    docoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6k2jrvsgGOO"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG2nrYF9gISI"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzK_KwRogKCq"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdbuew-rgMni",
        "outputId": "03ccefe7-b328-4c7c-b681-b5c83676f966"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59CqbXGugPSE",
        "outputId": "17caf5e6-db96-47f7-9c4d-b57c751caceb"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjMgMygJgRLW"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMlLIlFfgTq0",
        "outputId": "d1e9ac7a-9e6f-4c97-ee26-a591b673af05"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK4Ea6pvgV3Q"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVPhmRCEgXrZ",
        "outputId": "a05dbf5d-2e11-40ec-aa3e-8a0c82be204a"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLtpYI7IgZY3"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY8u-grzgbHf",
        "outputId": "7448774b-0d4d-4ee0-b23c-b95fd30aafbf"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP5gYF25gc--"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpdgD2ygfDl",
        "outputId": "98f7680d-42f3-4b6c-db6a-c43d1ae86bac"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.6278137890394814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSutOJRAghF2",
        "outputId": "1619a4e1-a537-43f6-ced3-c2911a05d7d1"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6405090137857901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geuy7U7pgmwy"
      },
      "source": [
        "# Truncate middle tokens in the beginining with max_length 140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCVxJRvTgoij"
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "decoder_sent=[]\n",
        "before_trunc=[]\n",
        "maxlen=140\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=False,\n",
        "                        padding=False,\n",
        "                        #max_length = maxlen,           # Pad & truncate all sentences.\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "   \n",
        "    before_trunc.append(encoded_dict['input_ids'])\n",
        "\n",
        "    ids = encoded_dict['input_ids']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['input_ids']=torch.tensor([ids])\n",
        "\n",
        "    ids = encoded_dict['attention_mask']\n",
        "    if len(ids)>=maxlen:\n",
        "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
        "    else:\n",
        "      ids = ids + ([0] * (maxlen-len(ids)))\n",
        "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #print(input_ids)\n",
        "        \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get the decoded sentence\n",
        "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "#print(input_ids)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P4ESJ1Fg0BA"
      },
      "source": [
        "labels=torch.tensor(df['label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEdWFXNqg2_c"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGLid5RDg8FW"
      },
      "source": [
        "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0B-W93nhAvm",
        "outputId": "79434c84-9052-41d5-aa9e-666ab0252417"
      },
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                           batch_size=16, \n",
        "                                           shuffle=True)\n",
        "for x, y,z in tmp_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(z.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 140])\n",
            "torch.Size([16, 140])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCC2gQ0zhDyy",
        "outputId": "2e77c6fa-60f3-4083-b7a2-15258e93b8da"
      },
      "source": [
        "model.config.to_dict()['hidden_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzDtu-0VhFy5"
      },
      "source": [
        " #last_hidden_states_all= torch.empty(256,768)\n",
        " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
        "   input_ids=input_ids.to(device)\n",
        "   attention_mask=attention_mask.to(device)\n",
        "   labels=labels.to(device)\n",
        "   with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "      \n",
        "    if i==0:\n",
        "        last_hidden_states_all = last_hidden_states\n",
        "        labels_all= labels\n",
        "        #print(last_hidden_states.size())\n",
        "    else:\n",
        "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
        "        labels_all=torch.cat((labels_all,labels),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7IPn3i9hIVc",
        "outputId": "4598af22-148e-4c4c-c988-11e89d19f29f"
      },
      "source": [
        "print(last_hidden_states_all.shape)\n",
        "print(labels_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11314, 768])\n",
            "torch.Size([11314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jA6g7ZhKMY"
      },
      "source": [
        "features = last_hidden_states_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngBJ7iojhMDZ",
        "outputId": "10ebd7b3-e157-49fc-a21b-bfe7e4b59013"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAQ-2B-hNro"
      },
      "source": [
        "labels = labels_all.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3WF7DfEhPbe",
        "outputId": "03d80201-b6fb-40ae-eb4c-77f507e957cc"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLXLTe8hRNm"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QztG6mYFhT2M",
        "outputId": "dcff0e53-c392-4a77-be10-453fbd2a6987"
      },
      "source": [
        " parameters = {'C': [0.001,0.01,0.1,1]}\n",
        " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.1}\n",
            "best scrores:  0.643134944018857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHXPWKYKhfDD",
        "outputId": "e51dcfdb-ebba-4a09-cbdf-34f93de3a093"
      },
      "source": [
        "grid_search.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.633085896076352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZjw5VpyhhEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}